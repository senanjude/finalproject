{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = pd.read_csv('latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109789, 19) (109789, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "data_final_vars=columns.columns.values.tolist()\n",
    "y1=['label']\n",
    "X1= ['has_php', 'has_htm', 'has_html', 'has_net', 'has_shorten', 'url_length', 'domain_length', 'no_of_fs', 'no_of_specials',\n",
    "     'no_of_schar_domain', 'no_of_schar_path', 'no_of_url_paths', 'no_of_punctuations', 'no_of_hypen', 'no_of_repetition', 'len_shortest_token',\n",
    "     'avg_len_token', 'ratio_vowel_consonant', 'std_token_len']\n",
    "\n",
    "data = columns[X1+y1]\n",
    "\n",
    "data = shuffle(data, random_state=int(time.time()))\n",
    "data = shuffle(data, random_state=int(time.time()))\n",
    "\n",
    "train, test = train_test_split(data,test_size=0.1)\n",
    "\n",
    "X = train[X1]\n",
    "Y = train[y1]\n",
    "\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, make_scorer, precision_score\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score), 'f1_score':make_scorer(f1_score), 'precision':make_scorer(precision_score), 'recall':make_scorer(recall_score)}\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906549717189933 0.9906203718940267 0.9844644317252658\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "classifier = neighbors.KNeighborsClassifier(weights='distance')\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "knn_acc = accuracy_score(y,out)\n",
    "knn_recall = recall_score(y,out,pos_label='malicious')\n",
    "knn_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(knn_acc, knn_f1, knn_recall)\n",
    "\n",
    "# 45sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9919665546356259 0.9918753108937158 0.9872916322825549\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "print(knn_acc, knn_f1, knn_recall)\n",
    "# pickle.dump(classifier, open('models/knn_model.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9963931469792606 0.9963642373161462 0.9950486879022941\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "dt1_acc = accuracy_score(y,out)\n",
    "dt1_recall = recall_score(y,out,pos_label='malicious')\n",
    "dt1_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(dt1_acc, dt1_f1, dt1_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968849905729977 0.996861060631092 0.9958739065852451\n"
     ]
    }
   ],
   "source": [
    "print(dt1_acc, dt1_f1, dt1_recall)\n",
    "# pickle.dump(classifier, open('models/dt1_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962291991146816 0.9962014863748968 0.9955438191120647\n"
     ]
    }
   ],
   "source": [
    "classifier = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "dt2_acc = accuracy_score(y,out)\n",
    "dt2_recall = recall_score(y,out,pos_label='malicious')\n",
    "dt2_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(dt2_acc, dt2_f1, dt2_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962291991146816 0.9962014863748968 0.9955438191120647\n"
     ]
    }
   ],
   "source": [
    "print(dt2_acc, dt2_f1, dt2_recall)\n",
    "# pickle.dump(classifier, open('models/dt2_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xenon\\AppData\\Local\\Temp/ipykernel_14760/4043683693.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979506516927616 0.9979340550367738 0.9965340815316058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "randf_acc = accuracy_score(y,out)\n",
    "randf_recall = recall_score(y,out,pos_label='malicious')\n",
    "randf_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(randf_acc, randf_f1, randf_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979506516927616 0.997934396430637 0.996699125268196\n"
     ]
    }
   ],
   "source": [
    "print(randf_acc, randf_f1, randf_recall)\n",
    "# pickle.dump(classifier, open('models/randf_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier = AdaBoostClassifier()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "ada_acc = accuracy_score(y,out)\n",
    "ada_recall = recall_score(y,out,pos_label='malicious')\n",
    "ada_f1 = f1_score(y,out,pos_label='malicious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "classifier = BaggingClassifier()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "bag_acc = accuracy_score(y,out)\n",
    "bag_recall = recall_score(y,out,pos_label='malicious')\n",
    "bag_f1 = f1_score(y,out,pos_label='malicious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "gradboost_acc = accuracy_score(y,out)\n",
    "gradboost_recall = recall_score(y,out,pos_label='malicious')\n",
    "gradboost_f1 = f1_score(y,out,pos_label='malicious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [0.98840952 1.41147733 0.81532884 0.85809898 1.23382759]\n",
      "score_time [0.13535953 0.0707643  0.06283092 0.10472107 0.10176063]\n",
      "test_accuracy [0.99216776 0.99393633 0.99469429 0.99216776 0.99342937]\n",
      "test_f1_score [0.99214991 0.99391789 0.99453836 0.99229814 0.99332991]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "classifier = ExtraTreesClassifier()\n",
    "# classifier.fit(X, Y)\n",
    "\n",
    "# x = test[X1]\n",
    "# y = test[y1]\n",
    "# out = classifier.predict(x)\n",
    "\n",
    "# extratree_acc = accuracy_score(y,out)\n",
    "# extratree_recall = recall_score(y,out,pos_label='malicious')\n",
    "# extratree_f1 = f1_score(y,out,pos_label='malicious')\n",
    "\n",
    "results = cross_validate(estimator=classifier, X=X, y=Y, scoring= scoring, cv=kfold)\n",
    "for i,j in results.items():\n",
    "  print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "classifier = HistGradientBoostingClassifier()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "histgrad_acc = accuracy_score(y,out)\n",
    "histgrad_recall = recall_score(y,out,pos_label='malicious')\n",
    "histgrad_f1 = f1_score(y,out,pos_label='malicious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445202364711233 0.943097014925373 0.9249771271729186\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "svm_acc = accuracy_score(y,out)\n",
    "svm_recall = recall_score(y,out,pos_label='malicious')\n",
    "svm_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(svm_acc, svm_f1, svm_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954524783992724 0.9521988527724664 0.9205175600739371\n"
     ]
    }
   ],
   "source": [
    "print(svm_acc, svm_f1, svm_recall)\n",
    "# pickle.dump(classifier, open('models/svm_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7849823756045577 0.7419576979832759 0.6223799306816307\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "classifier = naive_bayes.GaussianNB()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "nb1_acc = accuracy_score(y,out)\n",
    "nb1_recall = recall_score(y,out,pos_label='malicious')\n",
    "nb1_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(nb1_acc, nb1_f1, nb1_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9213278763074124 0.9201661282879555 0.8654513888888888\n"
     ]
    }
   ],
   "source": [
    "print(nb1_acc, nb1_f1, nb1_recall)\n",
    "# pickle.dump(classifier, open('models/nb1_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8963029756537421 0.8991469345451647 0.9199021207177814\n"
     ]
    }
   ],
   "source": [
    "classifier = naive_bayes.BernoulliNB(binarize=2.0)\n",
    "\n",
    "data = shuffle(data)\n",
    "data = shuffle(data)\n",
    "\n",
    "train, test = train_test_split(data,test_size=0.1)\n",
    "\n",
    "X = train[X1]\n",
    "Y = train[y1]\n",
    "\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "x = test[X1]\n",
    "y = test[y1]\n",
    "out = classifier.predict(x)\n",
    "\n",
    "nb2_acc = accuracy_score(y,out)\n",
    "nb2_recall = recall_score(y,out,pos_label='malicious')\n",
    "nb2_f1 = f1_score(y,out,pos_label='malicious')\n",
    "print(nb2_acc, nb2_f1, nb2_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065497171899336 0.9086099086099088 0.9285597247255448\n"
     ]
    }
   ],
   "source": [
    "print(nb2_acc, nb2_f1, nb2_recall)\n",
    "pickle.dump(classifier, open('models/nb2_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = [['KNN', knn_acc, knn_f1, knn_recall],\n",
    "          ['DT1', dt1_acc, dt1_f1, dt1_recall],\n",
    "          ['DT2', dt2_acc, dt2_f1, dt2_recall],\n",
    "          ['RandF', randf_acc, randf_f1, randf_recall],\n",
    "          ['AdaB', ada_acc, ada_f1, ada_recall],\n",
    "          ['Bag', bag_acc, bag_f1, bag_recall],\n",
    "          ['Grad', gradboost_acc, gradboost_f1, gradboost_recall],\n",
    "          ['ExtraT', extratree_acc, extratree_f1, extratree_recall],\n",
    "          ['HistG', histgrad_acc, histgrad_f1, histgrad_recall],\n",
    "          ['Svm', svm_acc, svm_f1, svm_recall],\n",
    "          ['Nb1', nb1_acc, nb1_f1, nb1_recall],\n",
    "          ['Nb2', nb2_acc, nb2_f1, nb2_recall]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tAccuracy\tF1 Score\tRecall\n",
      "HistG\t99.409%\t\t99.429%\t\t99.124%\n",
      "ExtraT\t99.272%\t\t99.299%\t\t99.299%\n",
      "RandF\t99.045%\t\t99.079%\t\t98.948%\n",
      "DT2\t98.772%\t\t98.818%\t\t98.948%\n",
      "Bag\t98.681%\t\t98.723%\t\t98.247%\n",
      "Grad\t98.590%\t\t98.634%\t\t98.072%\n",
      "DT1\t98.408%\t\t98.462%\t\t98.160%\n",
      "AdaB\t97.908%\t\t97.970%\t\t97.283%\n",
      "KNN\t97.863%\t\t97.921%\t\t97.020%\n",
      "Svm\t94.588%\t\t94.593%\t\t91.236%\n",
      "Nb1\t91.542%\t\t91.325%\t\t85.802%\n",
      "Nb2\t84.084%\t\t83.286%\t\t76.424%\n"
     ]
    }
   ],
   "source": [
    "metric_acc = sorted(metric, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print(\"Name\\tAccuracy\\tF1 Score\\tRecall\")\n",
    "for model in metric_acc:\n",
    "  print(\"{}\\t{:.3f}%\\t\\t{:.3f}%\\t\\t{:.3f}%\".format(model[0],model[1]*100, model[2]*100, model[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tAccuracy\tF1 Score\tRecall\n",
      "HistG\t99.409%\t\t99.429%\t\t99.124%\n",
      "ExtraT\t99.272%\t\t99.299%\t\t99.299%\n",
      "RandF\t99.045%\t\t99.079%\t\t98.948%\n",
      "DT2\t98.772%\t\t98.818%\t\t98.948%\n",
      "Bag\t98.681%\t\t98.723%\t\t98.247%\n",
      "Grad\t98.590%\t\t98.634%\t\t98.072%\n",
      "DT1\t98.408%\t\t98.462%\t\t98.160%\n",
      "AdaB\t97.908%\t\t97.970%\t\t97.283%\n",
      "KNN\t97.863%\t\t97.921%\t\t97.020%\n",
      "Svm\t94.588%\t\t94.593%\t\t91.236%\n",
      "Nb1\t91.542%\t\t91.325%\t\t85.802%\n",
      "Nb2\t84.084%\t\t83.286%\t\t76.424%\n"
     ]
    }
   ],
   "source": [
    "metric_f1 = sorted(metric, key=lambda x:x[2], reverse=True)\n",
    "\n",
    "print(\"Name\\tAccuracy\\tF1 Score\\tRecall\")\n",
    "for model in metric_f1:\n",
    "  print(\"{}\\t{:.3f}%\\t\\t{:.3f}%\\t\\t{:.3f}%\".format(model[0],model[1]*100, model[2]*100, model[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tAccuracy\tF1 Score\tRecall\n",
      "ExtraT\t99.272%\t\t99.299%\t\t99.299%\n",
      "HistG\t99.409%\t\t99.429%\t\t99.124%\n",
      "DT2\t98.772%\t\t98.818%\t\t98.948%\n",
      "RandF\t99.045%\t\t99.079%\t\t98.948%\n",
      "Bag\t98.681%\t\t98.723%\t\t98.247%\n",
      "DT1\t98.408%\t\t98.462%\t\t98.160%\n",
      "Grad\t98.590%\t\t98.634%\t\t98.072%\n",
      "AdaB\t97.908%\t\t97.970%\t\t97.283%\n",
      "KNN\t97.863%\t\t97.921%\t\t97.020%\n",
      "Svm\t94.588%\t\t94.593%\t\t91.236%\n",
      "Nb1\t91.542%\t\t91.325%\t\t85.802%\n",
      "Nb2\t84.084%\t\t83.286%\t\t76.424%\n"
     ]
    }
   ],
   "source": [
    "metric_recall = sorted(metric, key=lambda x:x[3], reverse=True)\n",
    "\n",
    "print(\"Name\\tAccuracy\\tF1 Score\\tRecall\")\n",
    "for model in metric_recall:\n",
    "  print(\"{}\\t{:.3f}%\\t\\t{:.3f}%\\t\\t{:.3f}%\".format(model[0],model[1]*100, model[2]*100, model[3]*100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3b730a9d7272a4f898f107daded6fab7115ce50b35b786d03fa41c7f88ce0f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
